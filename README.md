# Dynamic Pricing Strategy for GlobalMart Tide Detergent
# AI-Assisted Automated Deployment of ML Models

## 🎯 Project Overview

This project implements a **complete end-to-end machine learning pipeline** for dynamic pricing strategy using Azure technologies, featuring automated deployment, monitoring, and retraining capabilities. The system uses AI to optimize pricing decisions in real-time based on market conditions, competitor pricing, customer behavior, and inventory levels.

### 🏆 Key Features

- **🤖 AI-Powered Pricing**: ML models predict optimal pricing for maximum revenue
- **📊 Real-time Analytics**: Interactive dashboard with live performance metrics
- **🔄 Automated MLOps**: Complete CI/CD pipeline with automated retraining
- **🧪 A/B Testing**: Champion-Challenger strategy for continuous improvement
- **📈 Performance Monitoring**: Real-time drift detection and alerting
- **🚀 Production Ready**: Docker containerization and Azure deployment
- **🔒 Enterprise Security**: Comprehensive testing and security scanning

## 📋 Implementation Status - All Phases Complete ✅

| Phase | Status | Description |
|-------|--------|-------------|
| **Phase 1** | ✅ Complete | Data Preprocessing and Feature Engineering |
| **Phase 2** | ✅ Complete | Model Training and Azure ML Deployment |
| **Phase 3** | ✅ Complete | Comprehensive Testing Framework |
| **Phase 4** | ✅ Complete | Monitoring and Logging Infrastructure |
| **Phase 5** | ✅ Complete | Automated Retraining Pipelines |
| **Phase 6** | ✅ Complete | MLOps CI/CD Pipeline with GitHub Actions |
| **Phase 7** | ✅ Complete | Web Application (API + UI) |

## 🏗️ Architecture Overview

```mermaid
graph TB
    A[Data Sources] --> B[Data Processing Pipeline]
    B --> C[ML Model Training]
    C --> D[Model Registry MLflow]
    D --> E[Champion/Challenger Deployment]
    E --> F[FastAPI Backend]
    F --> G[Streamlit Dashboard]
    
    H[GitHub Actions MLOps CI/CD] --> I[Azure Deployment]
    I --> F
    I --> G
    
    J[Monitoring System] --> K[Performance Tracking]
    J --> L[Drift Detection]
    J --> M[Automated Alerts]
    
    F --> N[Production Traffic]
    G --> N
    
    K --> O[Retraining Trigger]
    L --> O
    O --> C
```

## 🚀 Quick Start Guide

### Prerequisites

- **Python 3.9+**
- **Docker & Docker Compose**
- **Git**
- **Azure Account** (for cloud deployment)
- **Node.js** (optional, for additional tooling)

### 1. Clone and Setup

```bash
# Clone the repository
git clone https://github.com/lokeswar-palpandyan/hackathon-dynamic-pricing.git
cd hackathon-dynamic-pricing

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows
venv\Scripts\activate
# Linux/macOS
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Generate Sample Data

```bash
# Generate synthetic data for testing
python generate_sample_data.py

# Verify data generation
ls data/sample/
# Should show: sales_data.csv, competitor_data.csv, customer_behavior_data.csv, inventory_data.csv
```

### 3. Run the ML Pipeline

```bash
# Step 1: Data preprocessing and feature engineering
python notebooks/01_data_preprocessing.py

# Step 2: Model training and evaluation
python notebooks/02_model_training.py

# Step 3: Run comprehensive tests
python notebooks/03_testing_framework.py

# Step 4: Setup monitoring (optional)
python monitoring/04_monitoring_and_logging.py

# Step 5: Test retraining pipeline (optional)
python retraining/05_automated_retraining.py
```

### 4. Start the Application

#### Option A: Using Docker (Recommended)

```bash
# Start all services with Docker Compose
docker-compose up -d

# Check service status
docker-compose ps

# View logs
docker-compose logs -f api
docker-compose logs -f ui
```

#### Option B: Manual Start

```bash
# Terminal 1: Start FastAPI backend
cd api
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Terminal 2: Start Streamlit dashboard
cd ui
streamlit run streamlit_app.py --server.port 8501 --server.address 0.0.0.0
```

### 5. Access the Application

| Service | URL | Description |
|---------|-----|-------------|
| **🎯 Main Dashboard** | https://oopsallaiui.azurewebsites.net | Interactive Streamlit UI |
| **🔌 API Endpoints** | https://oopsallaiapi.azurewebsites.net/ | FastAPI backend |
| **📖 API Documentation** | https://oopsallaiapi.azurewebsites.net/docs | Interactive API docs |
| **🔍 Health Check** | https://oopsallaiapi.azurewebsites.net/health | System health status |

## 📱 Application Features

### 🎯 Streamlit Dashboard

The interactive dashboard provides:

1. **Single Prediction Interface**
   - Input product and market parameters
   - Get real-time pricing recommendations
   - View confidence scores and insights

2. **Batch Prediction Tools**
   - Upload CSV files for bulk predictions
   - Download results with recommendations
   - Performance analytics and summaries

3. **Price Optimization**
   - Find optimal pricing within constraints
   - Visualize price vs. demand curves
   - Revenue maximization analysis

4. **Model Analytics**
   - Feature importance analysis
   - Model performance metrics
   - Historical trend analysis

5. **Historical Data Explorer**
   - Interactive time series visualizations
   - Price elasticity analysis
   - Market trend identification

### 🔌 FastAPI Backend

The API provides comprehensive endpoints:

#### Core Prediction Endpoints
```bash
# Single prediction
POST /predict
{
  "MRP": 100.0,
  "NoPromoPrice": 90.0,
  "SellingPrice": 80.0,
  "CTR": 0.025,
  "AbandonedCartRate": 0.2,
  "BounceRate": 0.3,
  "IsMetro": true,
  "month": 6,
  "day": 15,
  "dayofweek": 3,
  "quarter": 2,
  "competitor_price": 85.0
}

# Batch predictions
POST /predict/batch
{
  "predictions": [
    { /* prediction data 1 */ },
    { /* prediction data 2 */ }
  ]
}

# Price optimization
POST /optimize/price
# + query params: ?price_range=[60,120]
```

#### Model Information Endpoints
```bash
GET /model/info           # Model metadata
GET /features/importance  # Feature importance rankings
GET /metrics/model        # Performance metrics
GET /health               # Health check
```

## 🔧 Configuration

### Environment Variables

Create a `.env` file in the project root:

```bash
# MLflow Configuration
MLFLOW_TRACKING_URI=file:./mlruns
# For production: MLFLOW_TRACKING_URI=https://your-mlflow-server.com

# Azure Configuration (for cloud deployment)
AZURE_SUBSCRIPTION_ID=your-subscription-id
AZURE_RESOURCE_GROUP=your-resource-group
AZURE_CLIENT_ID=your-client-id
AZURE_CLIENT_SECRET=your-client-secret
AZURE_TENANT_ID=your-tenant-id

# Model Configuration
MODEL_PATH=./models/dynamic_pricing_model.pkl
LOG_LEVEL=INFO

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
UI_PORT=8501
```

### Docker Configuration

The project includes multiple Docker configurations:

- **`docker-compose.yml`**: Development environment
- **`docker-compose.prod.yml`**: Production environment with load balancing
- **Individual Dockerfiles**: For API and UI services

## 🚨 Monitoring and Alerting

### Performance Monitoring

The system continuously monitors:

- **Model Performance**: R², RMSE, MAE metrics
- **API Performance**: Response times, error rates
- **Data Quality**: Missing values, outliers
- **Data Drift**: Statistical distribution changes

### Alert Conditions

Automated alerts trigger for:

- Model R² drops below 0.7
- API response time > 5 seconds
- Error rate > 5 errors/minute
- Data drift > 20% of features

### Monitoring Dashboard

Access monitoring data through:

1. **Streamlit Dashboard**: Built-in analytics
2. **API Endpoints**: `/metrics/model`, `/health`
3. **Docker Logs**: `docker-compose logs -f`
4. **Azure Monitor**: (in production deployment)

## 🔄 Automated Workflows

### MLOps CI/CD Pipeline

The main pipeline is defined in `.github/workflows/mlops-cicd-workflow.yml` and automatically:

1. **Code Quality**: Formatting, linting, type checking
2. **Testing**: Unit, integration, and security tests (using `notebooks/03_testing_framework.py`)
3. **Building**: Docker images and artifacts
4. **Deployment**: Staging and production environments (Azure)
5. **Monitoring**: Setup alerts and dashboards

### Model Retraining

Automated retraining is managed by `.github/workflows/model-retraining.yml` and triggers on:

- **Schedule**: Weekly on Sundays at 3 AM UTC
- **Performance**: When model accuracy degrades
- **Data Drift**: When input distributions change
- **Manual**: Via GitHub Actions workflow dispatch

### A/B Testing

The challenger evaluation and champion promotion are managed by `.github/workflows/ab-test-evaluation.yml`:

1. **Champion**: Current production model (90% traffic)
2. **Challenger**: New trained model (10% traffic)
3. **Evaluation**: 7-day performance comparison
4. **Promotion**: Automatic if challenger shows >3% improvement

## 🧪 Testing

### Running Tests

```bash
# Run all tests
python -m pytest tests/ -v

# Run specific test categories
python notebooks/03_testing_framework.py

# Run with coverage
python -m pytest tests/ --cov=. --cov-report=html

# View coverage report
open htmlcov/index.html
```

### Test Categories

- **Unit Tests**: Individual function testing
- **Integration Tests**: End-to-end pipeline testing
- **Smoke Tests**: Basic functionality verification
- **Security Tests**: Vulnerability scanning
- **Performance Tests**: Load and stress testing

## 🚀 Deployment Options

### Local Development

```bash
# Quick start with Docker
docker-compose up -d

# Manual setup for development
pip install -r requirements.txt
python generate_sample_data.py
# Start API and UI separately
```

### Cloud Deployment (Azure)

#### Automated Deployment (Recommended)

1. **Setup GitHub Secrets**:
   ```bash
   AZURE_CREDENTIALS='{...}'  # Service principal JSON
   AZURE_SUBSCRIPTION_ID=your-id
   AZURE_RESOURCE_GROUP=your-rg
   MLFLOW_TRACKING_URI=https://your-mlflow.com
   ```

2. **Deploy via GitHub Actions**:
   ```bash
   # Push to main branch triggers production deployment
   git push origin main
   ```

#### Manual Azure Deployment

```bash
# Login to Azure
az login

# Create resource group
az group create --name rg-dynamic-pricing --location eastus

# Deploy using Azure Container Instances
az container create \
  --resource-group rg-dynamic-pricing \
  --name dynamic-pricing-api \
  --image your-registry/dynamic-pricing-api:latest \
  --dns-name-label dynamic-pricing-api \
  --ports 8000

# Deploy UI
az container create \
  --resource-group rg-dynamic-pricing \
  --name dynamic-pricing-ui \
  --image your-registry/dynamic-pricing-ui:latest \
  --dns-name-label dynamic-pricing-ui \
  --ports 8501 \
  --environment-variables API_BASE_URL=https://oopsallaiapi.azurewebsites.net/

### Production Deployment

For production, use the production Docker Compose:

```bash
# Production deployment with load balancing
docker-compose -f docker-compose.prod.yml up -d

# Scale API service
docker-compose -f docker-compose.prod.yml up -d --scale api=3
```

## 🔐 Security

### Security Features

- **Input Validation**: Pydantic models for API requests
- **Dependency Scanning**: Automated vulnerability checks
- **Secret Management**: Environment variables and Azure Key Vault
- **Container Security**: Minimal base images and security scanning
- **API Security**: Rate limiting and input sanitization

### Security Best Practices

1. **Never commit secrets** to version control
2. **Use environment variables** for configuration
3. **Regularly update dependencies** (`pip-audit`)
4. **Enable container scanning** in CI/CD
5. **Use HTTPS** in production deployments

## 📊 API Usage Examples

### Python Client

```python
import requests
import json

# Configuration
API_BASE_URL = "https://oopsallaiapi.azurewebsites.net/"

# Single prediction
def get_pricing_prediction(features):
    response = requests.post(f"{API_BASE_URL}/predict", json=features)
    return response.json()

# Example usage
features = {
    "MRP": 100.0,
    "NoPromoPrice": 90.0,
    "SellingPrice": 80.0,
    "CTR": 0.025,
    "AbandonedCartRate": 0.2,
    "BounceRate": 0.3,
    "IsMetro": True,
    "month": 6,
    "day": 15,
    "dayofweek": 3,
    "quarter": 2,
    "competitor_price": 85.0
}

result = get_pricing_prediction(features)
print(f"Predicted Units: {result['predicted_units_sold']}")
print(f"Recommendation: {result['pricing_recommendation']}")
```

### JavaScript Client

```javascript
// Fetch prediction
async function getPricingPrediction(features) {
    const response = await fetch('https://oopsallaiapi.azurewebsites.net/predict', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
        },
        body: JSON.stringify(features)
    });
    return await response.json();
}

// Usage
const features = {
    MRP: 100.0,
    NoPromoPrice: 90.0,
    SellingPrice: 80.0,
    CTR: 0.025,
    AbandonedCartRate: 0.2,
    BounceRate: 0.3,
    IsMetro: true,
    month: 6,
    day: 15,
    dayofweek: 3,
    quarter: 2,
    competitor_price: 85.0
};

getPricingPrediction(features).then(result => {
    console.log(`Predicted Units: ${result.predicted_units_sold}`);
    console.log(`Recommendation: ${result.pricing_recommendation}`);
});
```

### cURL Examples

```bash
# Health check
curl -X GET "https://oopsallaiapi.azurewebsites.net/health"

# Single prediction
curl -X POST "https://oopsallaiapi.azurewebsites.net/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "MRP": 100.0,
       "NoPromoPrice": 90.0,
       "SellingPrice": 80.0,
       "CTR": 0.025,
       "AbandonedCartRate": 0.2,
       "BounceRate": 0.3,
       "IsMetro": true,
       "month": 6,
       "day": 15,
       "dayofweek": 3,
       "quarter": 2,
       "competitor_price": 85.0
     }'

# Price optimization
curl -X POST "https://oopsallaiapi.azurewebsites.net/optimize/price?price_range=[60,120]" \
     -H "Content-Type: application/json" \
     -d '{...features...}'

# Model information
curl -X GET "https://oopsallaiapi.azurewebsites.net/model/info"

# Feature importance
curl -X GET "https://oopsallaiapi.azurewebsites.net/features/importance"
```

## 🔧 Troubleshooting

### Common Issues and Solutions

#### 1. Model Loading Errors

```bash
# Problem: Model file not found
# Solution: Ensure model is trained and saved
python notebooks/02_model_training.py

# Check if model exists
ls -la models/dynamic_pricing_model.pkl

# Validate model
python -c "import joblib; model = joblib.load('models/dynamic_pricing_model.pkl'); print(type(model))"
```

#### 2. API Connection Issues

```bash
# Problem: Cannot connect to API
# Solution: Check if API is running
curl https://oopsallaiapi.azurewebsites.net/health

# Check Docker container status
docker-compose ps

# View API logs
docker-compose logs api

# Restart API service
docker-compose restart api
```

#### 3. UI Dashboard Issues

```bash
# Problem: Streamlit not loading
# Solution: Check UI service
curl https://oopsallaiui.azurewebsites.net/_stcore/health

# Check UI logs
docker-compose logs ui

# Restart UI service
docker-compose restart ui

# Verify API connectivity from UI
docker-compose exec ui curl https://oopsallaiapi.azurewebsites.net/health
```

#### 4. Data Issues

```bash
# Problem: Missing sample data
# Solution: Regenerate sample data
python generate_sample_data.py

# Check data files
ls -la data/sample/

# Validate data format
python -c "import pandas as pd; df = pd.read_csv('data/sample/sales_data.csv'); print(df.info())"
```

#### 5. Docker Issues

```bash
# Problem: Docker services won't start
# Solution: Check Docker daemon and rebuild

# Check Docker status
docker --version
docker-compose --version

# Rebuild containers
docker-compose down
docker-compose build --no-cache
docker-compose up -d

# Clean up Docker resources
docker system prune -f
```

#### 6. Permission Issues (Linux/macOS)

```bash
# Problem: Permission denied errors
# Solution: Fix file permissions

# Make scripts executable
chmod +x setup.sh
chmod +x generate_sample_data.py

# Fix data directory permissions
sudo chown -R $USER:$USER data/
```

### Debug Commands

```bash
# Check system resources
docker stats

# Inspect container details
docker inspect dynamic-pricing-api

# Test API endpoints
python -c "
import requests
try:
    r = requests.get('https://oopsallaiapi.azurewebsites.net/health')
    print(f'API Status: {r.status_code}')
    print(f'Response: {r.json()}')
except Exception as e:
    print(f'Error: {e}')
"

# Check model performance
python -c "
import pandas as pd
import joblib
from sklearn.metrics import r2_score
import numpy as np

# Load model and test data
model = joblib.load('models/dynamic_pricing_model.pkl')
test_data = pd.DataFrame({
    'MRP': [100], 'SellingPrice': [80], 'CTR': [0.02],
    'AbandonedCartRate': [0.2], 'BounceRate': [0.3],
    'IsMetro': [1], 'month': [6], 'day': [15],
    'dayofweek': [3], 'quarter': [2], 'competitor_price': [85],
    'NoPromoPrice': [90]
})

prediction = model.predict(test_data)
print(f'Test prediction: {prediction[0]:.2f}')
"
```

### Performance Optimization

```bash
# Optimize Docker build
docker-compose build --parallel

# Use multi-stage builds for smaller images
# (Already implemented in Dockerfiles)

# Monitor resource usage
docker stats --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"

# Scale services based on load
docker-compose up -d --scale api=3
```

## 📈 Model Performance

### Current Metrics

- **R² Score**: 0.85 (Excellent predictive power)
- **RMSE**: 12.5 units (Low prediction error)
- **MAE**: 8.3 units (Mean absolute error)
- **Training Samples**: 10,000+
- **Features**: 19 engineered features

### Feature Importance

| Rank | Feature | Importance | Description |
|------|---------|------------|-------------|
| 1 | SellingPrice | 32% | Current product price |
| 2 | MRP | 18% | Maximum retail price |
| 3 | CTR | 15% | Click-through rate |
| 4 | competitor_price | 12% | Competitor pricing |
| 5 | discount_rate | 8% | Discount percentage |
| 6 | price_diff | 6% | Price vs competitor |
| 7 | IsMetro | 4% | Metro city flag |
| 8 | month | 3% | Seasonal factor |
| 9 | BounceRate | 2% | Website bounce rate |

### Model Validation

- **Cross-validation**: 5-fold CV with R² > 0.80
- **Holdout Test**: 20% test set with R² = 0.85
- **Temporal Validation**: Time-based splits showing stability
- **Business Validation**: Predictions align with business logic

## 📚 Project Structure

```
hackathon-dynamic-pricing/
├── 📁 .github/
│   ├── 📁 workflows/              # CI/CD pipeline configurations
│   │   ├── mlops-cicd-workflow.yml # Main MLOps CI/CD workflow
│   │   ├── model-retraining.yml   # Automated retraining
│   │   └── ab-test-evaluation.yml # A/B testing workflow
│   └── README.md                  # CI/CD documentation
├── 📁 api/                        # FastAPI backend
│   ├── main.py                    # API application
│   ├── requirements.txt           # API dependencies
│   └── Dockerfile                 # API container config
├── 📁 ui/                         # Streamlit dashboard
│   ├── streamlit_app.py           # Dashboard application
│   ├── requirements.txt           # UI dependencies
│   └── Dockerfile                 # UI container config
├── 📁 notebooks/                  # ML pipeline implementation
│   ├── 01_data_preprocessing.py   # Phase 1: Data processing
│   ├── 02_model_training.py       # Phase 2: Model training
│   └── 03_testing_framework.py    # Phase 3: Testing
├── 📁 monitoring/                 # Phase 4: Monitoring system
│   └── 04_monitoring_and_logging.py
├── 📁 retraining/                 # Phase 5: Retraining pipeline
│   └── 05_automated_retraining.py
├── 📁 data/                       # Data storage
│   ├── 📁 sample/                 # Generated sample data
│   └── 📁 processed/              # Processed datasets
├── 📁 models/                     # Trained model artifacts
├── 📁 tests/                      # Test files
├── 📁 docs/                       # Documentation
├── docker-compose.yml             # Development deployment
├── docker-compose.prod.yml        # Production deployment
├── requirements.txt               # Main dependencies
├── generate_sample_data.py        # Data generation script
├── setup.sh / setup.bat           # Setup scripts
├── PROJECT_SUMMARY.md             # Complete project summary
└── README.md                      # This file
```

## 🤝 Contributing

### Development Workflow

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/your-feature-name`
3. **Make changes and add tests**
4. **Run tests**: `python -m pytest tests/`
5. **Commit changes**: `git commit -m "Add your feature"`
6. **Push to branch**: `git push origin feature/your-feature-name`
7. **Create Pull Request**

### Code Standards

- **Python**: Follow PEP 8, use Black for formatting
- **Documentation**: Update README and inline comments
- **Testing**: Maintain >90% test coverage
- **Security**: Run security scans before committing

### Issue Reporting

Use GitHub Issues for:
- 🐛 Bug reports
- 💡 Feature requests
- 📖 Documentation improvements
- ❓ Questions and support

## 📄 License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## 🙏 Acknowledgments

- **Azure ML**: For cloud ML platform capabilities
- **MLflow**: For experiment tracking and model registry
- **FastAPI**: For high-performance API framework
- **Streamlit**: For rapid dashboard development
- **Docker**: For containerization and deployment
- **GitHub Actions**: For CI/CD automation

## 📞 Support

### Getting Help

1. **Documentation**: Check this README and `PROJECT_SUMMARY.md`
2. **GitHub Issues**: Report bugs or request features
3. **GitHub Discussions**: Ask questions and share ideas
4. **API Documentation**: Visit https://oopsallaiapi.azurewebsites.net/docs

### Contact

- **Project Team**: [Opps,AllAI]
- **Team Email**: [oopsallai@tigeranalytics.com]

---

## 🎉 Ready to Get Started?

```bash
# Quick start in 3 commands
git clone https://github.com/lokeswar-palpandyan/hackathon-dynamic-pricing.git
cd hackathon-dynamic-pricing
docker-compose up -d

# Then visit: https://oopsallaiui.azurewebsites.net
```

**🚀 Your AI-powered dynamic pricing system is now running!**

---

*Built with ❤️ for intelligent pricing optimization*