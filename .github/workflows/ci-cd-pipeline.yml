    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install azure-ai-ml
    
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
    
    - name: Validate and register model
      run: |
        python -c "
        import mlflow
        import mlflow.sklearn
        from azure.ai.ml import MLClient
        from azure.identity import DefaultAzureCredential
        import os
        import json
        
        # Set MLflow tracking URI
        mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])
        
        # Get the latest model from the current run
        experiment = mlflow.get_experiment_by_name('/Users/databricks/dynamic_pricing_experiment')
        if experiment:
            runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id], order_by=['start_time DESC'], max_results=1)
            if not runs.empty:
                latest_run_id = runs.iloc[0]['run_id']
                
                # Load model for validation
                model_uri = f'runs:/{latest_run_id}/model'
                model = mlflow.sklearn.load_model(model_uri)
                
                # Validate model performance
                import pandas as pd
                import numpy as np
                from sklearn.metrics import r2_score
                
                # Generate test data
                np.random.seed(42)
                test_data = pd.DataFrame({
                    'MRP': np.random.uniform(80, 120, 100),
                    'NoPromoPrice': np.random.uniform(70, 110, 100),
                    'SellingPrice': np.random.uniform(60, 100, 100),
                    'CTR': np.random.uniform(0.01, 0.05, 100),
                    'AbandonedCartRate': np.random.uniform(0.1, 0.3, 100),
                    'BounceRate': np.random.uniform(0.2, 0.5, 100),
                    'IsMetro': np.random.choice([0, 1], 100),
                    'month': np.random.randint(1, 13, 100),
                    'day': np.random.randint(1, 29, 100),
                    'dayofweek': np.random.randint(1, 8, 100),
                    'quarter': np.random.randint(1, 5, 100),
                    'competitor_price': np.random.uniform(65, 105, 100)
                })
                
                predictions = model.predict(test_data)
                
                # Validation criteria
                if len(predictions) == len(test_data) and all(p >= 0 for p in predictions):
                    print('✓ Model validation passed')
                    
                    # Register model if validation passes
                    try:
                        model_version = mlflow.register_model(model_uri, 'dynamic_pricing_model_prod')
                        print(f'✓ Model registered as version {model_version.version}')
                        
                        # Tag the model version
                        client = mlflow.MlflowClient()
                        client.set_model_version_tag(
                            'dynamic_pricing_model_prod',
                            model_version.version,
                            'github_sha',
                            os.environ.get('GITHUB_SHA', 'unknown')
                        )
                        client.set_model_version_tag(
                            'dynamic_pricing_model_prod',
                            model_version.version,
                            'deployment_stage',
                            'production_candidate'
                        )
                        
                    except Exception as e:
                        print(f'Warning: Model registration failed: {e}')
                else:
                    print('✗ Model validation failed')
                    exit(1)
            else:
                print('No recent runs found')
        else:
            print('Experiment not found')
        "

  # Job 7: Deploy to Production
  deploy-production:
    runs-on: ubuntu-latest
    needs: model-validation
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
    
    - name: Deploy API to Azure App Service
      run: |
        # Create App Service Plan
        az appservice plan create \
          --name asp-dynamic-pricing-prod \
          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
          --sku B1 \
          --is-linux
        
        # Create Web App
        az webapp create \
          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
          --plan asp-dynamic-pricing-prod \
          --name dynamic-pricing-api-prod-${{ github.run_number }} \
          --deployment-container-image-name dynamic-pricing-api:${{ github.sha }}
        
        # Configure App Settings
        az webapp config appsettings set \
          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
          --name dynamic-pricing-api-prod-${{ github.run_number }} \
          --settings \
            MLFLOW_TRACKING_URI=${{ env.MLFLOW_TRACKING_URI }} \
            AZURE_SUBSCRIPTION_ID=${{ env.AZURE_SUBSCRIPTION_ID }} \
            AZURE_RESOURCE_GROUP=${{ env.AZURE_RESOURCE_GROUP }} \
            WEBSITES_PORT=8000
    
    - name: Deploy UI to Azure Static Web Apps
      run: |
        # For Streamlit UI, we'll deploy to Azure Container Instances
        az container create \
          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
          --name dynamic-pricing-ui-prod \
          --image dynamic-pricing-ui:${{ github.sha }} \
          --dns-name-label dynamic-pricing-ui-prod-${{ github.run_number }} \
          --ports 8501 \
          --environment-variables \
            API_BASE_URL=https://dynamic-pricing-api-prod-${{ github.run_number }}.azurewebsites.net
    
    - name: Update production model endpoint
      run: |
        python -c "
        import mlflow
        import os
        
        # Set MLflow tracking URI
        mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])
        
        # Get the latest registered model
        client = mlflow.MlflowClient()
        try:
            latest_version = client.get_latest_versions('dynamic_pricing_model_prod', stages=['None'])[0]
            
            # Transition to Production stage
            client.transition_model_version_stage(
                name='dynamic_pricing_model_prod',
                version=latest_version.version,
                stage='Production',
                archive_existing_versions=True
            )
            
            print(f'Model version {latest_version.version} promoted to Production')
            
        except Exception as e:
            print(f'Error promoting model: {e}')
        "
    
    - name: Run production smoke tests
      run: |
        sleep 120  # Wait for deployment
        
        # Get production URLs
        API_URL=$(az webapp show \
          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
          --name dynamic-pricing-api-prod-${{ github.run_number }} \
          --query hostNames[0] -o tsv)
        
        # Test production API
        curl -f https://$API_URL/health
        curl -f https://$API_URL/model/info
        
        # Test prediction endpoint with sample data
        curl -X POST https://$API_URL/predict \
          -H "Content-Type: application/json" \
          -d '{
            "MRP": 100.0,
            "NoPromoPrice": 90.0,
            "SellingPrice": 80.0,
            "CTR": 0.025,
            "AbandonedCartRate": 0.2,
            "BounceRate": 0.3,
            "IsMetro": true,
            "month": 6,
            "day": 15,
            "dayofweek": 3,
            "quarter": 2,
            "competitor_price": 85.0
          }'

  # Job 8: Automated Retraining Check
  retraining-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Check retraining triggers
      run: |
        python -c "
        import requests
        import json
        import os
        
        # Check if retraining is needed
        try:
            # This would check monitoring data and performance metrics
            # For demo, we'll simulate the check
            
            print('Checking retraining triggers...')
            
            # Simulate checking model performance
            performance_degraded = False  # Would check actual metrics
            data_drift_detected = False   # Would check drift metrics
            
            if performance_degraded or data_drift_detected:
                print('Retraining triggered!')
                
                # Trigger retraining workflow
                # In a real scenario, this would call the retraining API
                print('Would trigger retraining workflow')
                
                # Create issue for manual review
                print('Creating issue for manual review')
                
            else:
                print('No retraining needed at this time')
                
        except Exception as e:
            print(f'Error checking retraining triggers: {e}')
        "
    
    - name: Create issue if retraining needed
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: 'Automated Retraining Required',
            body: 'The automated retraining check has detected that model retraining may be required. Please review the monitoring data and consider triggering a retraining pipeline.',
            labels: ['ml-ops', 'retraining', 'automated']
          })

  # Job 9: Cleanup and Notifications
  cleanup-and-notify:
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: always()
    
    steps:
    - name: Clean up staging resources
      if: success()
      run: |
        az group delete --name rg-dynamic-pricing-staging --yes --no-wait
    
    - name: Notify team on success
      if: success() && github.ref == 'refs/heads/main'
      uses: actions/github-script@v6
      with:
        script: |
          const deploymentUrl = `https://dynamic-pricing-api-prod-${{ github.run_number }}.azurewebsites.net`;
          const uiUrl = `http://dynamic-pricing-ui-prod-${{ github.run_number }}.eastus.azurecontainer.io:8501`;
          
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `Production Deployment Successful - Build ${{ github.run_number }}`,
            body: `
            ## 🚀 Production Deployment Completed Successfully
            
            **Build:** ${{ github.run_number }}
            **Commit:** ${{ github.sha }}
            **Branch:** ${{ github.ref }}
            
            ### Deployed Services:
            - **API:** ${deploymentUrl}
            - **UI Dashboard:** ${uiUrl}
            
            ### What was deployed:
            - ✅ ML Model Pipeline
            - ✅ FastAPI Backend
            - ✅ Streamlit Dashboard
            - ✅ Model registered in MLflow
            - ✅ Production smoke tests passed
            
            ### Next Steps:
            - Monitor application performance
            - Review automated retraining schedule
            - Check monitoring dashboards
            `,
            labels: ['deployment', 'production', 'success']
          })
    
    - name: Notify team on failure
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `Deployment Failed - Build ${{ github.run_number }}`,
            body: `
            ## ❌ Deployment Failed
            
            **Build:** ${{ github.run_number }}
            **Commit:** ${{ github.sha }}
            **Branch:** ${{ github.ref }}
            
            Please check the workflow logs for details and fix the issues.
            
            [View Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            `,
            labels: ['deployment', 'failure', 'urgent']
          })

  # Job 10: Performance Monitoring Setup
  setup-monitoring:
    runs-on: ubuntu-latest
    needs: deploy-production
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Setup Azure Application Insights
      run: |
        # Create Application Insights
        az monitor app-insights component create \
          --app dynamic-pricing-insights \
          --location eastus \
          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
          --application-type web
        
        # Get instrumentation key
        INSTRUMENTATION_KEY=$(az monitor app-insights component show \
          --app dynamic-pricing-insights \
          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
          --query instrumentationKey -o tsv)
        
        echo "Application Insights configured with key: $INSTRUMENTATION_KEY"
    
    - name: Setup monitoring alerts
      run: |
        # Create metric alerts for API performance
        az monitor metrics alert create \
          --name "API Response Time High" \
          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
          --scopes /subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.Web/sites/dynamic-pricing-api-prod-${{ github.run_number }} \
          --condition "avg responseTime > 5" \
          --description "Alert when API response time exceeds 5 seconds"
        
        # Create alert for error rate
        az monitor metrics alert create \
          --name "API Error Rate High" \
          --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
          --scopes /subscriptions/${{ env.AZURE_SUBSCRIPTION_ID }}/resourceGroups/${{ env.AZURE_RESOURCE_GROUP }}/providers/Microsoft.Web/sites/dynamic-pricing-api-prod-${{ github.run_number }} \
          --condition "avg Http5xx > 5" \
          --description "Alert when API error rate exceeds 5 errors per minute"